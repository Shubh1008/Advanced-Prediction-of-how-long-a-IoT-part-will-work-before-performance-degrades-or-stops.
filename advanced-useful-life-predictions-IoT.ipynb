{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_test = utils.load_data('data/test_FD004.txt')\n",
    "\n",
    "es_test, _ = make_entityset(data_test, nclusters, kmeans=kmeans)\n",
    "fm_test = ft.calculate_feature_matrix(entityset=es_test, features=features, verbose=True, chunk_size='cutoff time')\n",
    "X = fm_test.copy().fillna(0)\n",
    "y = pd.read_csv('data/RUL_FD004.txt', sep=' ', header=-1, names=['RUL'], index_col=False)\n",
    "preds = regs[0].predict(X)\n",
    "print('Mean Abs Error: {:.2f}'.format(mean_absolute_error(preds, y)))\n",
    "\n",
    "\n",
    "from btb import HyperParameter, ParamTypes\n",
    "from btb.tuning import GP\n",
    "\n",
    "def run_btb(fm_list, n=30):\n",
    "    hyperparam_ranges = [\n",
    "            ('n_estimators', HyperParameter(ParamTypes.INT, [10, 200])),\n",
    "            ('max_feats', HyperParameter(ParamTypes.INT, [5, 50])),\n",
    "            ('nfeats', HyperParameter(ParamTypes.INT, [10, 70])),\n",
    "    ]\n",
    "    tuner = GP(hyperparam_ranges)\n",
    "\n",
    "    tested_parameters = np.zeros((n, len(hyperparam_ranges)), dtype=object)\n",
    "    scores = []\n",
    "    \n",
    "    print('[n_est, max_feats, nfeats]')\n",
    "    best = 45\n",
    "\n",
    "    for i in tqdm(range(n)):\n",
    "        hyperparams = tuner.propose()\n",
    "        cvscores, regs, selectors = pipeline_for_test(fm_list, hyperparams=hyperparams, do_selection=True)\n",
    "        bound = np.mean(cvscores)\n",
    "        tested_parameters[i, :] = hyperparams\n",
    "        tuner.add(hyperparams, -np.mean(cvscores))\n",
    "        if np.mean(cvscores) + np.std(cvscores) < best:\n",
    "            best = np.mean(cvscores)\n",
    "            best_hyperparams = hyperparams\n",
    "            best_reg = regs[0]\n",
    "            best_sel = selectors[0]\n",
    "            print('{}. {} -- Average MAE: {:.1f}, Std: {:.2f}'.format(i, \n",
    "                                                                      best_hyperparams, \n",
    "                                                                      np.mean(cvscores), \n",
    "                                                                      np.std(cvscores)))\n",
    "            print('Raw: {}'.format([float('{:.1f}'.format(s)) for s in cvscores]))\n",
    "\n",
    "    return best_hyperparams, (best_sel, best_reg)\n",
    "\n",
    "best_hyperparams, best_pipeline = run_btb(fm_list, n=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Abs Error on Test: 29.48\n",
      "1: MAX(recordings.sensor_measurement_13) [0.139]\n",
      "2: MAX(recordings.settings_clusters.LAST(recordings.sensor_measurement_13)) [0.104]\n",
      "3: MAX(recordings.sensor_measurement_11) [0.084]\n",
      "4: MAX(recordings.settings_clusters.LAST(recordings.sensor_measurement_11)) [0.083]\n",
      "5: COMPLEXITY(recordings.settings_clusters.LAST(recordings.sensor_measurement_8)) [0.071]\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = fm_test.copy().fillna(0)\n",
    "y = pd.read_csv('data/RUL_FD004.txt', sep=' ', header=-1, names=['RUL'], index_col=False)\n",
    "\n",
    "preds = best_pipeline[1].predict(best_pipeline[0].transform(X))\n",
    "score = mean_absolute_error(preds, y)\n",
    "print('Mean Abs Error on Test: {:.2f}'.format(score))\n",
    "most_imp_feats = utils.feature_importances(X.iloc[:, best_pipeline[0].support_], best_pipeline[1])\n",
    "\n",
    "from featuretools.primitives import Min\n",
    "old_fm, features = ft.dfs(entityset=es, \n",
    "                      target_entity='engines',\n",
    "                      agg_primitives=['last', 'max', 'min'],\n",
    "                      trans_primitives=[],\n",
    "                      cutoff_time=cutoff_time_list[0],\n",
    "                      max_depth=3,\n",
    "                      verbose=True)\n",
    "\n",
    "old_fm_list = [old_fm]\n",
    "for i in tqdm(range(1, splits)):\n",
    "    old_fm = ft.calculate_feature_matrix(entityset=make_entityset(data, nclusters, kmeans=kmeans)[0], \n",
    "                                     features=features, \n",
    "                                     cutoff_time=cutoff_time_list[i])\n",
    "    old_fm_list.append(fm)\n",
    "\n",
    "old_scores = []\n",
    "median_scores = []\n",
    "for fm in old_fm_list:\n",
    "    X = fm.copy().fillna(0)\n",
    "    y = X.pop('RUL')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    reg = RandomForestRegressor(n_estimators=10)\n",
    "    reg.fit(X_train, y_train)\n",
    "    preds = reg.predict(X_test)\n",
    "    old_scores.append(mean_absolute_error(preds, y_test))\n",
    "    \n",
    "    medianpredict = [np.median(y_train) for _ in y_test]\n",
    "    median_scores.append(mean_absolute_error(medianpredict, y_test))\n",
    "\n",
    "print([float('{:.1f}'.format(score)) for score in old_scores])\n",
    "print('Average MAE: {:.2f}, Std: {:.2f}\\n'.format(np.mean(old_scores), np.std(old_scores)))\n",
    "\n",
    "print([float('{:.1f}'.format(score)) for score in median_scores])\n",
    "print('Baseline by Median MAE: {:.2f}, Std: {:.2f}\\n'.format(np.mean(median_scores), np.std(median_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49.5, 52.8, 49.0, 49.5, 48.3]\n",
      "Baseline by Median MAE: 49.82, Std: 1.58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = pd.read_csv('data/RUL_FD004.txt', sep=' ', header=-1, names=['RUL'], index_col=False)\n",
    "median_scores_2 = []\n",
    "for ct in cutoff_time_list:\n",
    "    medianpredict2 = [np.median(ct['RUL'].values) for _ in y.values]\n",
    "    median_scores_2.append(mean_absolute_error(medianpredict2, y))\n",
    "print([float('{:.1f}'.format(score)) for score in median_scores_2])\n",
    "print('Baseline by Median MAE: {:.2f}, Std: {:.2f}\\n'.format(np.mean(median_scores_2), np.std(median_scores_2)))\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"output\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "fm.to_csv('output/advanced_train_feature_matrix.csv')\n",
    "cutoff_time_list[0].to_csv('output/advanced_train_label_times.csv')\n",
    "fm_test.to_csv('output/advanced_test_feature_matrix.csv')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": "\nimport numpy as np\nimport pandas as pd\nimport featuretools as ft\nimport utils\n\ndata_path = 'data/train_FD004.txt'\ndata = utils.load_data(data_path)\n\ndata.head()\n\nfrom tqdm import tqdm\n\nsplits = 5\ncutoff_time_list = []\n\nfor i in tqdm(range(splits)):\n    cutoff_time_list.append(utils.make_cutoff_times(data))\n\ncutoff_time_list[0].head()\n\nfrom sklearn.cluster import KMeans\n\nnclusters = 50\n\ndef make_entityset(data, nclusters, kmeans=None):\n    X = data[['operational_setting_1', 'operational_setting_2', 'operational_setting_3']]\n    if kmeans:\n        kmeans=kmeans\n    else:\n        kmeans = KMeans(n_clusters=nclusters).fit(X)\n    data['settings_clusters'] = kmeans.predict(X)\n    \n    es = ft.EntitySet('Dataset')\n    es.entity_from_dataframe(dataframe=data,\n                             entity_id='recordings',\n                             index='index',\n                             time_index='time')\n\n    es.normalize_entity(base_entity_id='recordings', \n                        new_entity_id='engines',\n                        index='engine_no')\n    \n    es.normalize_entity(base_entity_id='recordings', \n                        new_entity_id='settings_clusters',\n                        index='settings_clusters')\n    \n    return es, kmeans\nes, kmeans = make_entityset(data, nclusters)\nes\n\nes.plot()\n\nfrom featuretools.primitives import make_agg_primitive\nimport featuretools.variable_types as vtypes\n\nfrom tsfresh.feature_extraction.feature_calculators import (number_peaks, mean_abs_change, \n                                                            cid_ce, last_location_of_maximum, length)\n\n\nComplexity = make_agg_primitive(lambda x: cid_ce(x, False),\n                              input_types=[vtypes.Numeric],\n                              return_type=vtypes.Numeric,\n                              name=\"complexity\")\n\nfm, features = ft.dfs(entityset=es, \n                      target_entity='engines',\n                      agg_primitives=['last', 'max', Complexity],\n                      trans_primitives=[],\n                      chunk_size=.26,\n                      cutoff_time=cutoff_time_list[0],\n                      max_depth=3,\n                      verbose=True)\n\nfm.to_csv('advanced_fm.csv')\nfm.head()\n\nfm_list = [fm]\nfor i in tqdm(range(1, splits)):\n    fm = ft.calculate_feature_matrix(entityset=make_entityset(data, nclusters, kmeans=kmeans)[0], \n                                     features=features, \n                                     chunk_size=.26, \n                                     cutoff_time=cutoff_time_list[i])\n    fm_list.append(fm)\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.feature_selection import RFE\ndef pipeline_for_test(fm_list, hyperparams={'n_estimators':100, 'max_feats':50, 'nfeats':50}, do_selection=False):\n    scores = []\n    regs = []\n    selectors = []\n    for fm in fm_list:\n        X = fm.copy().fillna(0)\n        y = X.pop('RUL')\n        reg = RandomForestRegressor(n_estimators=int(hyperparams['n_estimators']), \n                                    max_features=min(int(hyperparams['max_feats']), \n                                                     int(hyperparams['nfeats'])))\n        X_train, X_test, y_train, y_test = train_test_split(X, y)\n        if do_selection:\n            reg2 = RandomForestRegressor(n_estimators=10, n_jobs=3)\n            selector = RFE(reg2, int(hyperparams['nfeats']), step=25)\n            selector.fit(X_train, y_train)\n            X_train = selector.transform(X_train)\n            X_test = selector.transform(X_test)\n            selectors.append(selector)\n        reg.fit(X_train, y_train)\n        regs.append(reg)\n        \n        preds = reg.predict(X_test)\n        scores.append(mean_absolute_error(preds, y_test))\n    return scores, regs, selectors    \nscores, regs, selectors = pipeline_for_test(fm_list)\nprint([float('{:.1f}'.format(score)) for score in scores])\nprint('Average MAE: {:.1f}, Std: {:.2f}\\n'.format(np.mean(scores), np.std(scores)))\n\nmost_imp_feats = utils.feature_importances(fm_list[0], regs[0])"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
